# -*- coding: utf-8 -*-
"""Speech_Task2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TnL4kz27gWFQw9kubD-U2FGRbPmydmma
"""

!pip install pandas
!pip install librosa
!pip install plotly
!pip install matplotlib
!pip install mutagen
!pip install pillow

import os
import librosa
import torch
import zipfile
import mutagen
import mutagen.wave
import torchaudio
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from torchaudio.transforms import Spectrogram
import IPython.display
import matplotlib.pyplot as plt
import plotly.graph_objects as go
from PIL import Image

def create_dataset_df(csv_file):
    dataset_df = pd.read_csv(csv_file)
    filepaths = []
    for i, row in dataset_df.iterrows():
        filepaths.append(os.path.join('UrbanSound8K/audio', 'fold'+str(row['fold']), row['slice_file_name']))
    dataset_df['filepath'] = filepaths
    return dataset_df

dataset_df = create_dataset_df('/content/UrbanSound8K.csv')
dataset_df.head()

# Unzip dataset
!wget https://zenodo.org/record/1203745/files/UrbanSound8K.tar.gz -O urban8k.tgz
!tar -xzf urban8k.tgz
!rm urban8k.tgz

!cat UrbanSound8K/UrbanSound8K_README.txt

dataset_df.groupby('class').slice_file_name.count()

def get_audio_metadata_mutagen(filepath):
    metadata = {}
    f = mutagen.wave.WAVE(filepath)
    metadata['length'] = f.info.length
    metadata['bitrate'] = f.info.bitrate
    metadata['channels'] = f.info.channels
    metadata['sample_rate'] = f.info.sample_rate
    metadata['bits_per_sample'] = f.info.bits_per_sample
    return metadata


def compute_audio_statistics(dataset_df):
    metadata_dict = {'length': [], 'bitrate': [], 'channels': [], 'sample_rate': [], 'bits_per_sample': []}
    # Extract metadata
    for filepath in dataset_df['filepath']:
        metadata = get_audio_metadata_mutagen(filepath)
        for key in metadata_dict.keys():
            metadata_dict[key].append(metadata[key])
    # Add new columns to dataframe
    for key in metadata_dict.keys():
        dataset_df[key] = metadata_dict[key]

    return dataset_df

dataset_df = dataset_df.drop(columns=['fold', 'slice_file_name', 'fsID', 'start', 'end'])

audio_statistics_df = compute_audio_statistics(dataset_df)

audio_statistics_df.describe()

audio_statistics_df['sample_rate'].value_counts(), audio_statistics_df['bits_per_sample'].value_counts()

audio_statistics_df.groupby('class').describe()

# Randomly select one sample of each class
# Select one sample per class
random_samples = dataset_df.groupby('class').sample(1)

# Store file paths and labels separately
audio_samples = random_samples['filepath'].tolist()
labels = random_samples['class'].tolist()

# Determine the number of samples (classes)
num_classes = len(audio_samples)

# Define subplot grid
num_cols = 2
num_rows = (num_classes + 1) // num_cols  # Adjust number of rows dynamically

# Initialize figure and axes
fig, axs = plt.subplots(num_rows, num_cols, figsize=(15, 3 * num_rows))

# Ensure axs is a 2D array
if num_rows == 1:
    axs = axs.reshape(1, -1)

# Store waveforms and sample rates
waveforms = []
sample_rates = []

# Load audio files
for audio_path in audio_samples:
    waveform, sample_rate = librosa.load(audio_path)
    waveforms.append(waveform)
    sample_rates.append(sample_rate)

# Plot waveforms
for index, (waveform, sample_rate, label) in enumerate(zip(waveforms, sample_rates, labels)):
    row, col = divmod(index, num_cols)
    librosa.display.waveshow(waveform, sr=sample_rate, ax=axs[row, col])
    axs[row, col].set_title(f'{label}')

# Hide unused subplots
for i in range(index + 1, num_rows * num_cols):
    row, col = divmod(i, num_cols)
    fig.delaxes(axs[row, col])

fig.tight_layout()
plt.show()

"""## HANN , HAMMING Window"""

from scipy.io import wavfile

# read from storage
filename = '/content/7061-6-0-0.wav'
fs, data = wavfile.read(filename)

window_length_ms = 30
window_length = int(np.round(fs*window_length_ms/1000))

n = np.linspace(0.5,window_length-0.5,num=window_length)

# windowing function
windowing_fn = np.sin(np.pi*n/window_length)**2 # sine-window


datawin = data[38000:(38000+window_length)]
datawin = datawin/np.max(np.abs(datawin)) # normalize

plt.plot(n*1000/fs,datawin)
plt.xlabel('Time (ms)')
plt.ylabel('Amplitude')
plt.title('A window of a signal without a windowing function (i.e. rectangular window)')
plt.axis([-10.,45.,-1.,1.])
plt.tight_layout()
plt.show()

nx = np.concatenate(([-1000,0.],n,[window_length,window_length+1000]))
# Reshape [0., 0.] to have the same number of dimensions as datawin
zeros_array = np.zeros((2, datawin.shape[1]))  # Assuming datawin has shape (x, 2)

datax = np.concatenate((zeros_array, datawin, zeros_array)) # Updated concatenation line
plt.plot(nx*1000/fs,datax)
plt.xlabel('Time (ms)')
plt.ylabel('Amplitude')
plt.title('Signal with a rectangular window looks as if it had a discontinuity at the borders')
plt.axis([-10.,45.,-1.,1.])
plt.tight_layout()
plt.show()

nx = np.concatenate(([-1000,0.],n,[window_length,window_length+1000]))
# Reshape [0., 0.] to have the same number of dimensions as datawin * windowing_fn
zeros_array = np.zeros((2, datawin.shape[1]))  # Assuming datawin has shape (x, 2)

datax = np.concatenate((zeros_array, datawin*windowing_fn[:, None], zeros_array)) # Updated concatenation line

plt.plot(nx*1000/fs,datax,label='Windowed signal')
plt.plot(n*1000/fs,windowing_fn,'--',label='Window function')
plt.legend()
plt.xlabel('Time (ms)')
plt.ylabel('Amplitude')
plt.title('Signal with a Hann window looks as if it would be continuous')
plt.axis([-10.,45.,-1.,1.])
plt.tight_layout()
plt.show()

import numpy as np
import matplotlib.pyplot as plt

# window parameters in milliseconds
window_length_ms = 30
fs = 16000

window_length = int(np.round(fs*window_length_ms/1000))

n = np.linspace(0.5,window_length-0.5,num=window_length)

# windowing function
windowing_fn = np.sin(np.pi*n/window_length)**2 # sine-window

plt.plot(n*1000/fs,windowing_fn)
plt.xlabel('Time (ms)')
plt.ylabel('Amplitude')
plt.title('A Hann-window of 30ms length')
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from scipy.io import wavfile


# read from storage
filename = '/content/7061-6-0-0.wav'
fs, data = wavfile.read(filename)
data = np.float64(data)

# window parameters in milliseconds
window_length_ms = 30
window_step_ms = window_length_ms/2

window_step = int(np.round(fs*window_step_ms/1000))
window_length = window_step*2
window_count = int(np.floor((data.shape[0]-window_length)/window_step)+1)

# windowing function
windowing_fn = np.sin(np.pi*np.linspace(0.5,window_length-0.5,num=window_length)/window_length) # half-sine window

n = np.linspace(0.5,window_length-0.5,num=window_length)

plt.plot(n/fs,windowing_fn)
plt.title('The Hann-window')
plt.xlabel('Time (s)')
plt.ylabel('Amplitude')
plt.show()

# Extract windows
window_matrix = np.zeros([window_length,window_count, data.shape[1]],dtype=np.float64) # Modified to accommodate stereo channels
for window_ix in range(window_count):
    for channel in range(data.shape[1]):  # Iterate through channels
        window_matrix[:,window_ix, channel] = np.multiply(windowing_fn,data[window_ix*window_step+np.arange(window_length), channel])


# Reconstruct
data_reconstructed = np.zeros_like(data)
for window_ix in range(window_count):
    for channel in range(data.shape[1]):  # Iterate through channels
        data_reconstructed[window_ix*window_step + np.arange(window_length), channel] += window_matrix[:,window_ix, channel]*windowing_fn


t = np.arange(0,np.float64(data.shape[0])/fs,1./fs)
plt.plot(t,data,label='Original')
plt.plot(t,data_reconstructed,label='Reconstructed')
plt.xlabel('Time (s)')
plt.ylabel('Amplitude')
plt.legend()
plt.title('Original and reconstructed signals')
plt.show()
plt.plot(t,data-data_reconstructed)
plt.xlabel('Time (s)')
plt.ylabel('Amplitude')
plt.title('Difference between original and reconstructed signals')
plt.show()

#Plotting of the results
fig,axs = plt.subplots(3,1)
fig.set_size_inches((10,10))
plt.subplots_adjust(hspace=0.5)

# Assuming 'M' represents a shift or offset, you'll need to define it.
# For example, if you want to shift the plot by 10 units, set M to 10.
M = 10  # Replace with your desired value for M

# Assuming 'h' represents the filter coefficients, you need to define it as well.
# This is just a placeholder, replace with the actual filter coefficients.
h = np.random.rand(len(n))  # Replace with your filter coefficients

# Assuming 'w', 'wc', and 'Hh' represent frequency domain variables,
# these also need to be defined.
# Replace these with your actual values.
w = np.linspace(-np.pi, np.pi, len(n))
wc = np.pi / 4  # Example cutoff frequency
Hh = np.fft.fft(h)

#Plot the modified filter coefficients
ax=axs[0]
# Removed 'use_line_collection' argument as it's no longer supported
ax.stem(n+M, h, basefmt='b-')
ax.set_xlabel("Sample number $n$",fontsize=20)
ax.set_ylabel(" $h_n$",fontsize=24)
ax.set_title('Truncated Impulse response $h_n$ of the Filter', fontsize=20)

#Plot the frequency response of the filter in linear units
ax=axs[1]
ax.plot(w-np.pi, abs(np.fft.fftshift(Hh)))
ax.axis(xmax=np.pi/2, xmin=-np.pi/2)
ax.vlines([-wc,wc], 0, 1.2, color='g', lw=2., linestyle='--',)
ax.hlines(1, -np.pi, np.pi, color='g', lw=2., linestyle='--',)
ax.set_xlabel(r"Normalized frequency $\omega$",fontsize=22)
ax.set_ylabel(r"$|H(\omega)| $",fontsize=22)
ax.set_title('Frequency response of $h_n$ ', fontsize=20)

#Plot the frequency response of the filter in dB
ax=axs[2]
ax.plot(w-np.pi, 20*np.log10(abs(np.fft.fftshift(Hh))))
ax.axis(ymin=-80,xmax=np.pi/2,xmin=-np.pi/2)
ax.vlines([-wc,wc], 10, -80, color='g', lw=2., linestyle='--',)
ax.hlines(0, -np.pi, np.pi, color='g', lw=2., linestyle='--',)
ax.set_xlabel(r"Normalized frequency $\omega$",fontsize=22)
ax.set_ylabel(r"$20\log_{10}|H(\omega)| $",fontsize=18)
ax.set_title('Frequency response of the Filter in dB', fontsize=20)

fig.tight_layout()
plt.show()

import numpy as np
import librosa
import librosa.display
import matplotlib.pyplot as plt

def STFT(win_type=None): # Make win_type optional and default to None
  n_fft = 1024  # Change n_fft to 1024 to match the window size
  hop_length = 512
  fig, axs = plt.subplots(5, 2, figsize=(20,20))
  index = 0
  n_s = 4
  for col in range(2):
      for row in range(5):
          audio_file, sample_rate = librosa.load(audio_samples[index])

          # Adjust window size to match n_fft or vice-versa
          # Use numpy.hanning instead of hann_window

          #Apply windowing function based on win_type or default to hanning
          if win_type == 'hann':
              window = np.hanning(n_fft)
          else:
              window = np.hanning(n_fft)  # Default to hanning if win_type is not 'hann'

          stft = librosa.stft(y=audio_file, n_fft=n_fft, hop_length=hop_length, window=window)


          S_db = librosa.amplitude_to_db(np.abs(stft), ref=np.max)
          librosa.display.specshow(S_db,
                              sr=n_fft,
                              hop_length=hop_length,
                              x_axis="time",
                              y_axis='log',
                              ax=axs[row][col])
          axs[row][col].set_title('{}'.format(labels[index]))
          index += 1
  fig.tight_layout()

STFT('hann')

STFT('hamming')

STFT('rectangular')

# Visualize 40 MFCCs
n_fft = 2048
# Librosa default is n_fft // 4
hop_length = 512
fig, axs = plt.subplots(5, 2, figsize=(20,20))
index = 0
n_s = 4
for col in range(2):
    for row in range(5):
        audio_file, sample_rate = librosa.load(audio_samples[index])
        # The mfcc function in librosa.feature expects keyword arguments, not positional arguments
        mfccs = librosa.feature.mfcc(y=audio_file,
                                    sr=sample_rate,
                                    n_fft=n_fft,
                                    n_mfcc=40)
        librosa.display.specshow(mfccs,
                             sr=n_fft,
                             hop_length=hop_length,
                             x_axis="time",
                             ax=axs[row][col])
        axs[row][col].set_title('{}'.format(labels[index]))
        index += 1
fig.tight_layout()

import csv

# Load the audio files and labels
audio_files = []
labels = []

# Load the labels from the csv file
label_dict = {}
with open("/content/UrbanSound8K.csv") as f:
    reader = csv.reader(f)
    next(reader)  # skip header row
    for row in reader:
        filename = row[0]
        label = row[7]  # label is in the 8th column (index 7)
        label_dict[filename] = label

# Loop through all the folders in the directory
for foldername in os.listdir("/content/UrbanSound8K/audio"):
    if foldername.endswith(".DS_Store"):  # skip csv files
        continue
    # Loop through all the audio files in the folder
    for filename in os.listdir("/content/UrbanSound8K/audio/{}".format(foldername)):
        # Skip non-audio files, specifically '.DS_Store'
        if filename == ".DS_Store":
            continue
        # Load the audio file
        data, sr = librosa.load("/content/UrbanSound8K/audio/{}/{}".format(foldername, filename), sr=None)

        # Get the label for the audio file
        label = label_dict[filename]

        audio_files.append((data, sr))
        labels.append(label)

def extract_mfcc(win_func, win_size=1024, hop_size=512):
  X = []
  max_length = 0

  for data, sr in audio_files:
      # Extract MFCCs
      D = librosa.stft(y=data, n_fft=win_size, hop_length=hop_size, window=win_func(win_size))
      mfccs = librosa.feature.mfcc(S=librosa.power_to_db(np.abs(D)), sr=sr, n_mfcc=13)
      mfccs_scaled = np.mean(mfccs.T,axis=0)
      X.append(mfccs_scaled)
  return X

import numpy as np
import scipy.signal

# Assuming you want to use numpy's hanning window
def hann_window(N):
    return np.hanning(N)

# Assuming you want to use scipy's hamming window
def hamming_window(N):
    # Use scipy.signal.windows.hamming instead of scipy.signal.hamming
    return scipy.signal.windows.hamming(N)

# Define a rectangular window function
def rectangular_window(N):
    return np.ones(N)

X_hann = extract_mfcc(hann_window)
X_hamming = extract_mfcc(hamming_window)
X_rect = extract_mfcc(rectangular_window)

X_hann = extract_mfcc(hann_window)
X_hamming = extract_mfcc(hamming_window)
X_rect = extract_mfcc(rectangular_window)

from sklearn.preprocessing import StandardScaler, LabelEncoder # Import necessary classes

# Create instances of the scaler and encoder
scaler = StandardScaler()
le = LabelEncoder()

X_hann = scaler.fit_transform(X_hann)
X_hamming = scaler.fit_transform(X_hamming)
X_rect = scaler.fit_transform(X_rect)

#y = labels
y_hann = le.fit_transform(labels)
y_hamming = le.fit_transform(labels)
y_rect = le.fit_transform(labels)

# Split the data into training and test sets
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X_hann, y_hann, test_size=0.3, random_state=42)

X_train, X_test, y_train, y_test = train_test_split(X_hamming, y_hamming, test_size=0.3, random_state=42)

X_train, X_test, y_train, y_test = train_test_split(X_rect, y_rect, test_size=0.3, random_state=42)

# import Classifiers
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier
from sklearn.linear_model import SGDClassifier
from sklearn.neural_network import MLPClassifier
from xgboost import XGBClassifier

from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, ConfusionMatrixDisplay

# Define the classifiers to use
classifiers = [
    KNeighborsClassifier(),
    DecisionTreeClassifier(),
    RandomForestClassifier(),
    AdaBoostClassifier(),
    GradientBoostingClassifier(),
    SGDClassifier(),
    MLPClassifier(),
    XGBClassifier()
]

# Create an empty DataFrame to store the results
results = pd.DataFrame(columns=['Classifier', 'Accuracy', 'Precision', 'Recall'])

# Loop through the classifiers
for clf in classifiers:
    # Fit the classifier to the training data
    clf.fit(X_train, y_train)

    # Evaluate the classifier on the test data
    y_pred = clf.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred, average="macro")
    recall = recall_score(y_test, y_pred, average="macro")

    # Store the results in the DataFrame
    results = pd.concat([results, pd.DataFrame([{'Classifier': clf.__class__.__name__,
                              'Accuracy': accuracy,
                              'Precision': precision,
                              'Recall': recall}])], ignore_index=True)

# Sort the DataFrame by the Accuracy column in descending order
results.sort_values(by='Accuracy', ascending=False, inplace=True)

# show the DataFrame
results

# Create and fit the model
model = RandomForestClassifier()
model.fit(X_train, y_train)

# Evaluate the classifier on the test data using the fitted model
y_pred = model.predict(X_test)
cm = confusion_matrix(y_test, y_pred)

# Plot the confusion matrix
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)
disp.plot()
plt.show()

# Function to compute STFT and display spectrogram
def plot_spectrogram(y, sr, window_func, window_size=1024, hop_size=512):
    # Apply STFT with the specified window function
    D = librosa.stft(y, n_fft=window_size, hop_length=hop_size, window=window_func(window_size))
    plt.figure(figsize=(12, 8))
    librosa.display.specshow(librosa.amplitude_to_db(np.abs(D), ref=np.max), y_axis='log', x_axis='time', sr=sr)
    plt.colorbar(format='%+2.0f dB')
    plt.title(f'Spectrogram with {window_func.__name__.capitalize()} Window')
    plt.show()

"""TASK B"""

!pip install SpeechRecognition

!pip install gTTS

!pip install git+https://github.com/openai/whisper.git

import numpy as np
import matplotlib.pyplot as plt

import librosa
import librosa.display
import soundfile as sf
import speech_recognition as sr

from jiwer import wer, cer
from IPython.display import Audio

import whisper

import csv
import os
import tempfile
import wave

from gtts import gTTS

"""Devotional"""

audio_signal, sample_rate = librosa.load('/content/Achyutam Keshavam Krishna Damodaram.wav', sr=None)

sample_rate

plt.figure(figsize=(12,4))
librosa.display.waveshow(audio_signal, sr=sample_rate)
plt.title('Waveform')
plt.xlabel('Time (s)')
plt.ylabel('Amplitude')
plt.show()

Audio('/content/Achyutam Keshavam Krishna Damodaram.wav')

"""Rap Song"""

audio_signal, sample_rate = librosa.load('/content/Millionaire - Glory 128 Kbps.wav', sr=None)

sample_rate

plt.figure(figsize=(12,4))
librosa.display.waveshow(audio_signal, sr=sample_rate)
plt.title('Waveform')
plt.xlabel('Time (s)')
plt.ylabel('Amplitude')
plt.show()

Audio('/content/Millionaire - Glory 128 Kbps.wav')

"""Romantic Song Rajesh Khanna"""

audio_signal, sample_rate = librosa.load('/content/O Mere Dil Ke Chain - Mere Jeevan Saathi 320 Kbps.wav', sr=None)

plt.figure(figsize=(12,4))
librosa.display.waveshow(audio_signal, sr=sample_rate)
plt.title('Waveform')
plt.xlabel('Time (s)')
plt.ylabel('Amplitude')
plt.show()

Audio('/content/O Mere Dil Ke Chain - Mere Jeevan Saathi 320 Kbps.wav')

audio_signal, sample_rate = librosa.load('/content/Hookah Bar Khiladi 786 128 Kbps.wav', sr=None)

plt.figure(figsize=(12,4))
librosa.display.waveshow(audio_signal, sr=sample_rate)
plt.title('Waveform')
plt.xlabel('Time (s)')
plt.ylabel('Amplitude')
plt.show()

Audio('/content/Hookah Bar Khiladi 786 128 Kbps.wav')

import numpy as np
import librosa
import librosa.display
import matplotlib.pyplot as plt
import scipy.signal  # Import scipy.signal


# Function to compute STFT and display spectrogram
def plot_spectrogram(y, sr, window_func, window_size=1024, hop_size=512):
    # Apply STFT with the specified window function
    D = librosa.stft(y, n_fft=window_size, hop_length=hop_size, window=window_func(window_size))
    plt.figure(figsize=(12, 8))
    librosa.display.specshow(librosa.amplitude_to_db(np.abs(D), ref=np.max), y_axis='log', x_axis='time', sr=sr)
    plt.colorbar(format='%+2.0f dB')
    plt.title(f'Spectrogram with {window_func.__name__.capitalize()} Window')
    plt.show()

# Define window functions
# Assuming you want to use numpy's hanning window
def hann_window(N):
    return np.hanning(N)

# Assuming you want to use scipy's hamming window
def hamming_window(N):
    # Use scipy.signal.windows.hamming instead of scipy.signal.hamming
    return scipy.signal.windows.hamming(N)

# Define a rectangular window function
def rectangular_window(N):
    return np.ones(N)

audio_file = '/content/O Mere Dil Ke Chain - Mere Jeevan Saathi 320 Kbps.wav'
y, sr = librosa.load(audio_file, sr=None)
# Generate spectrograms using different windowing techniques
plot_spectrogram(y, sr, hann_window)  # Now hann_window is defined
plot_spectrogram(y, sr, hamming_window)
plot_spectrogram(y, sr, rectangular_window)

audio_file = '/content/Millionaire - Glory 128 Kbps.wav'
y, sr = librosa.load(audio_file, sr=None)
# Generate spectrograms using different windowing techniques
plot_spectrogram(y, sr, hann_window)
plot_spectrogram(y, sr, hamming_window)
plot_spectrogram(y, sr, rectangular_window)

audio_file = '/content/O Mere Dil Ke Chain - Mere Jeevan Saathi 320 Kbps.wav'
y, sr = librosa.load(audio_file, sr=None)
# Generate spectrograms using different windowing techniques
plot_spectrogram(y, sr, hann_window)
plot_spectrogram(y, sr, hamming_window)
plot_spectrogram(y, sr, rectangular_window)

audio_file = '/content/Achyutam Keshavam Krishna Damodaram.wav'
y, sr = librosa.load(audio_file, sr=None)
# Generate spectrograms using different windowing techniques
plot_spectrogram(y, sr, hann_window)
plot_spectrogram(y, sr, hamming_window)
plot_spectrogram(y, sr, rectangular_window)